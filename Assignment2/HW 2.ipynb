{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_char_grams(k, filename):\n",
    "    grams = set()\n",
    "    with open(filename) as fp:\n",
    "        text = fp.read()\n",
    "        \n",
    "    i = 0\n",
    "    while i+k != len(text):\n",
    "        grams.add(text[i:i+k])\n",
    "        i += 1\n",
    "        \n",
    "    return grams\n",
    "\n",
    "\n",
    "def k_word_grams(k, filename):\n",
    "    grams = set()\n",
    "    with open(filename) as fp:\n",
    "        text = fp.read().split(' ')\n",
    "        \n",
    "    i = 0\n",
    "    while i+k != len(text):\n",
    "        grams.add(\" \".join(text[i:i+k]))\n",
    "        i += 1\n",
    "    \n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['text/D1.txt', 'text/D2.txt', 'text/D3.txt', 'text/D4.txt']\n",
    "\n",
    "G1 = {fname.split('/')[1]: k_char_grams(2, fname) for fname in fnames}\n",
    "G2 = {fname.split('/')[1]: k_char_grams(3, fname) for fname in fnames}\n",
    "G3 = {fname.split('/')[1]: k_word_grams(2, fname) for fname in fnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1\n",
      "D1.txt: # of grams:266\n",
      "D2.txt: # of grams:265\n",
      "D3.txt: # of grams:258\n",
      "D4.txt: # of grams:259\n",
      "\n",
      "G2\n",
      "D1.txt: # of grams:815\n",
      "D2.txt: # of grams:804\n",
      "D3.txt: # of grams:757\n",
      "D4.txt: # of grams:771\n",
      "\n",
      "G3\n",
      "D1.txt: # of grams:308\n",
      "D2.txt: # of grams:307\n",
      "D3.txt: # of grams:294\n",
      "D4.txt: # of grams:260\n"
     ]
    }
   ],
   "source": [
    "print('G1')\n",
    "print('\\n'.join([file + ': # of grams:' + str(len(grams)) for file, grams in G1.items()]))\n",
    "print()\n",
    "print('G2')\n",
    "print('\\n'.join([file + ': # of grams:' + str(len(grams)) for file, grams in G2.items()]))\n",
    "print()\n",
    "print('G3')\n",
    "print('\\n'.join([file + ': # of grams:' + str(len(grams)) for file, grams in G3.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(A, B):\n",
    "    return len(A.intersection(B))/len(A.union(B))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity for G1\n",
      "Similarity (D1.txt, D2.txt): 0.9962406015037594\n",
      "Similarity (D1.txt, D3.txt): 0.9124087591240876\n",
      "Similarity (D1.txt, D4.txt): 0.7326732673267327\n",
      "Similarity (D2.txt, D3.txt): 0.9157509157509157\n",
      "Similarity (D2.txt, D4.txt): 0.7293729372937293\n",
      "Similarity (D3.txt, D4.txt): 0.6950819672131148\n",
      "\n",
      "Jaccard similarity for G2\n",
      "Similarity (D1.txt, D2.txt): 0.9648058252427184\n",
      "Similarity (D1.txt, D3.txt): 0.7312775330396476\n",
      "Similarity (D1.txt, D4.txt): 0.35555555555555557\n",
      "Similarity (D2.txt, D3.txt): 0.7402452619843924\n",
      "Similarity (D2.txt, D4.txt): 0.3496143958868895\n",
      "Similarity (D3.txt, D4.txt): 0.3510167992926614\n",
      "\n",
      "Jaccard similarity for G3\n",
      "Similarity (D1.txt, D2.txt): 0.7672413793103449\n",
      "Similarity (D1.txt, D3.txt): 0.2754237288135593\n",
      "Similarity (D1.txt, D4.txt): 0.012477718360071301\n",
      "Similarity (D2.txt, D3.txt): 0.3008658008658009\n",
      "Similarity (D2.txt, D4.txt): 0.016129032258064516\n",
      "Similarity (D3.txt, D4.txt): 0.014652014652014652\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "print('Jaccard similarity for G1')\n",
    "for combo in itertools.combinations(G1.items(), 2):\n",
    "    print('Similarity ({}, {}): {}'.format(combo[0][0], combo[1][0], \n",
    "                                           jaccard_sim(combo[0][1], combo[1][1])))\n",
    "    \n",
    "print()\n",
    "print('Jaccard similarity for G2')\n",
    "for combo in itertools.combinations(G2.items(), 2):\n",
    "    print('Similarity ({}, {}): {}'.format(combo[0][0], combo[1][0], \n",
    "                                           jaccard_sim(combo[0][1], combo[1][1])))\n",
    "    \n",
    "print()\n",
    "print('Jaccard similarity for G3')\n",
    "for combo in itertools.combinations(G3.items(), 2):\n",
    "    print('Similarity ({}, {}): {}'.format(combo[0][0], combo[1][0], \n",
    "                                           jaccard_sim(combo[0][1], combo[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mersenne_prime = (1 << 61) - 1\n",
    "_max_hash = (1 << 32) - 1\n",
    "\n",
    "class min_hash:\n",
    "    def __init__(self, t, seed=1):\n",
    "        num_perm = t\n",
    "        self.seed = seed\n",
    "        self.hashvalues = np.full(num_perm, _max_hash, dtype=np.uint64)\n",
    "        generator = np.random.RandomState(self.seed)\n",
    "        self.permutations = np.array([(generator.randint(1, _mersenne_prime, dtype=np.uint64),\n",
    "                                       generator.randint(0, _mersenne_prime, dtype=np.uint64))\n",
    "                                       for _ in range(t)], dtype=np.uint64).T\n",
    "        \n",
    "    def update(self, gram):\n",
    "        hv = np.uint64(hash(gram))\n",
    "        #hv = struct.unpack('<I', hashlib.sha1(gram).digest()[:4])[0]\n",
    "        a, b = self.permutations\n",
    "        phv = np.bitwise_and((hv + b) , np.uint64(_max_hash))\n",
    "        self.hashvalues = np.minimum(phv, self.hashvalues)\n",
    "        \n",
    "    def jaccard(self, other):\n",
    "        return np.float(np.count_nonzero(self.hashvalues==other.hashvalues)) / np.float(len(self.hashvalues))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9770000000000008\n",
      "60 0.9640000000000011\n",
      "150 0.9625999999999999\n",
      "300 0.9650333333333329\n",
      "600 0.9648666666666668\n"
     ]
    }
   ],
   "source": [
    "ts = [20,60,150,300,600]\n",
    "rang = 100\n",
    "for t in ts:\n",
    "    _sum = 0\n",
    "    for r in range(rang):\n",
    "        seed = random.randint(0,2^31)\n",
    "        m1, m2 = min_hash(t, seed=seed), min_hash(t, seed=seed)\n",
    "        for gram in G2['D1.txt']:\n",
    "            m1.update(gram.encode('utf-8'))\n",
    "        for gram in G2['D2.txt']:\n",
    "            m2.update(gram.encode('utf-8'))\n",
    "\n",
    "        _sum += m1.jaccard(m2)\n",
    "    \n",
    "    print(t, _sum/rang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
